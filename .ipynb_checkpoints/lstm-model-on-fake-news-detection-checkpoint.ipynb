{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plastic-subscription",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-05-05T13:01:32.255852Z",
     "iopub.status.busy": "2021-05-05T13:01:32.253835Z",
     "iopub.status.idle": "2021-05-05T13:01:32.268533Z",
     "shell.execute_reply": "2021-05-05T13:01:32.267890Z"
    },
    "papermill": {
     "duration": 0.063104,
     "end_time": "2021-05-05T13:01:32.268697",
     "exception": false,
     "start_time": "2021-05-05T13:01:32.205593",
     "status": "completed"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sixth-pakistan",
   "metadata": {
    "papermill": {
     "duration": 0.036646,
     "end_time": "2021-05-05T13:01:32.342595",
     "exception": false,
     "start_time": "2021-05-05T13:01:32.305949",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<center>\n",
    "<span style=\"font-family:luxury; color:MediumVioletRed; font-size:45px;\"> FAKE NEWS CLASSIFIER </span>\n",
    "</center>   \n",
    "<center>\n",
    "<span style=\"font-family:luxury; color:Plum\t; font-size:30px;\"> LSTM Model </span>\n",
    "</center> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blessed-exemption",
   "metadata": {
    "papermill": {
     "duration": 0.036302,
     "end_time": "2021-05-05T13:01:32.415515",
     "exception": false,
     "start_time": "2021-05-05T13:01:32.379213",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<span style=\"font-family:luxury; color:MediumVioletRed; font-size:30px;\"> Reading train data</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modified-prague",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-05T13:01:32.495906Z",
     "iopub.status.busy": "2021-05-05T13:01:32.494689Z",
     "iopub.status.idle": "2021-05-05T13:01:32.498411Z",
     "shell.execute_reply": "2021-05-05T13:01:32.497830Z"
    },
    "papermill": {
     "duration": 0.046159,
     "end_time": "2021-05-05T13:01:32.498549",
     "exception": false,
     "start_time": "2021-05-05T13:01:32.452390",
     "status": "completed"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "delayed-jason",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-05T13:01:32.582568Z",
     "iopub.status.busy": "2021-05-05T13:01:32.581892Z",
     "iopub.status.idle": "2021-05-05T13:01:34.986796Z",
     "shell.execute_reply": "2021-05-05T13:01:34.987308Z"
    },
    "papermill": {
     "duration": 2.45026,
     "end_time": "2021-05-05T13:01:34.987477",
     "exception": false,
     "start_time": "2021-05-05T13:01:32.537217",
     "status": "completed"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train= pd.read_csv(\"train.csv\")\n",
    "print(\"data shape :\", train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efficient-solid",
   "metadata": {
    "papermill": {
     "duration": 0.039285,
     "end_time": "2021-05-05T13:01:35.066575",
     "exception": false,
     "start_time": "2021-05-05T13:01:35.027290",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<span style=\"font-family:luxury; color:MediumVioletRed; font-size:30px;\"> Reading test data</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-eclipse",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-05T13:01:35.148991Z",
     "iopub.status.busy": "2021-05-05T13:01:35.148240Z",
     "iopub.status.idle": "2021-05-05T13:01:35.688920Z",
     "shell.execute_reply": "2021-05-05T13:01:35.688072Z"
    },
    "papermill": {
     "duration": 0.584647,
     "end_time": "2021-05-05T13:01:35.689085",
     "exception": false,
     "start_time": "2021-05-05T13:01:35.104438",
     "status": "completed"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test= pd.read_csv(\"test.csv\")\n",
    "print(\"data shape :\", test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transsexual-extension",
   "metadata": {
    "papermill": {
     "duration": 0.040888,
     "end_time": "2021-05-05T13:01:35.770952",
     "exception": false,
     "start_time": "2021-05-05T13:01:35.730064",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<span style=\"color:Olive; font-size:15px;\">\n",
    "Removing records with missing values.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "completed-cooling",
   "metadata": {
    "papermill": {
     "duration": 0.040626,
     "end_time": "2021-05-05T13:01:35.852223",
     "exception": false,
     "start_time": "2021-05-05T13:01:35.811597",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<span style=\"font-family:luxury; color:MediumVioletRed; font-size:30px;\"> Combined data</span><br>\n",
    "<span style=\"color:Olive; font-size:15px;\">\n",
    "    Concating both train and test dataset so that text preprocessing before giving it to model can be done simultaneously on both of them.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fourth-basics",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-05T13:01:35.945491Z",
     "iopub.status.busy": "2021-05-05T13:01:35.944264Z",
     "iopub.status.idle": "2021-05-05T13:01:35.970771Z",
     "shell.execute_reply": "2021-05-05T13:01:35.971367Z"
    },
    "papermill": {
     "duration": 0.079181,
     "end_time": "2021-05-05T13:01:35.971541",
     "exception": false,
     "start_time": "2021-05-05T13:01:35.892360",
     "status": "completed"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# creating an additional column to distinguish between the datasets after concating\n",
    "train[\"train/test\"]= \"train\"\n",
    "test[\"train/test\"]= \"test\"\n",
    "\n",
    "# concating\n",
    "combined_data= pd.concat([train, test], axis=0)\n",
    "print(\"combined data shape :\", combined_data.shape)\n",
    "combined_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secure-parcel",
   "metadata": {
    "papermill": {
     "duration": 0.040804,
     "end_time": "2021-05-05T13:01:36.054072",
     "exception": false,
     "start_time": "2021-05-05T13:01:36.013268",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<span style=\"font-family:luxury; color:MediumVioletRed; font-size:30px;\"> Data Preprocessing</span><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finite-associate",
   "metadata": {
    "papermill": {
     "duration": 0.041115,
     "end_time": "2021-05-05T13:01:36.137707",
     "exception": false,
     "start_time": "2021-05-05T13:01:36.096592",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<span style=\"color:Olive; font-size:15px;\">\n",
    "    The \"text\" column is the column which contains the news, so we only need to preprocess this, we'll also take \"train/test\"\n",
    "column so that both the datasets can be distinguished later\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hired-directive",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-05T13:01:36.227613Z",
     "iopub.status.busy": "2021-05-05T13:01:36.225191Z",
     "iopub.status.idle": "2021-05-05T13:01:36.241797Z",
     "shell.execute_reply": "2021-05-05T13:01:36.242322Z"
    },
    "papermill": {
     "duration": 0.064174,
     "end_time": "2021-05-05T13:01:36.242511",
     "exception": false,
     "start_time": "2021-05-05T13:01:36.178337",
     "status": "completed"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_data= combined_data.drop(columns=[\"id\",\"author\" , \"title\", \"label\"], axis=1)\n",
    "combined_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "linear-projection",
   "metadata": {
    "papermill": {
     "duration": 0.041881,
     "end_time": "2021-05-05T13:01:36.326211",
     "exception": false,
     "start_time": "2021-05-05T13:01:36.284330",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<span style=\"font-family:luxury; color:MediumVioletRed; font-size:25px;\"> Check Missing Values</span><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appreciated-instruction",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-05T13:01:36.434095Z",
     "iopub.status.busy": "2021-05-05T13:01:36.433039Z",
     "iopub.status.idle": "2021-05-05T13:01:36.440254Z",
     "shell.execute_reply": "2021-05-05T13:01:36.440828Z"
    },
    "papermill": {
     "duration": 0.072536,
     "end_time": "2021-05-05T13:01:36.440998",
     "exception": false,
     "start_time": "2021-05-05T13:01:36.368462",
     "status": "completed"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nearby-opinion",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-05T13:01:36.539961Z",
     "iopub.status.busy": "2021-05-05T13:01:36.538018Z",
     "iopub.status.idle": "2021-05-05T13:01:36.542951Z",
     "shell.execute_reply": "2021-05-05T13:01:36.542462Z"
    },
    "papermill": {
     "duration": 0.057941,
     "end_time": "2021-05-05T13:01:36.543078",
     "exception": false,
     "start_time": "2021-05-05T13:01:36.485137",
     "status": "completed"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# replace missing values\n",
    "combined_data= combined_data.fillna(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metric-yellow",
   "metadata": {
    "papermill": {
     "duration": 0.040964,
     "end_time": "2021-05-05T13:01:36.625178",
     "exception": false,
     "start_time": "2021-05-05T13:01:36.584214",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<span style=\"color:Olive; font-size:15px;\">\n",
    "The first step in data preprocessing is to consider only alphabets and removing the numbers, special characters and converting all the words to lower case\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noted-greene",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-05T13:01:36.714940Z",
     "iopub.status.busy": "2021-05-05T13:01:36.713910Z",
     "iopub.status.idle": "2021-05-05T13:01:48.406648Z",
     "shell.execute_reply": "2021-05-05T13:01:48.407135Z"
    },
    "papermill": {
     "duration": 11.741964,
     "end_time": "2021-05-05T13:01:48.407314",
     "exception": false,
     "start_time": "2021-05-05T13:01:36.665350",
     "status": "completed"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def clean(text):\n",
    "    # removing all the characters other than alphabets\n",
    "    cleaned_text= re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    # converting text to lower case\n",
    "    cleaned_text= cleaned_text.lower()\n",
    "    return cleaned_text\n",
    "\n",
    "# Now creating a separate column which contains the above function applied to \"text\" column\n",
    "combined_data[\"cleaned(only alphabets)\"]= combined_data[\"text\"].apply(lambda x : clean(x) )\n",
    "combined_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smooth-northwest",
   "metadata": {
    "papermill": {
     "duration": 0.042693,
     "end_time": "2021-05-05T13:01:48.492263",
     "exception": false,
     "start_time": "2021-05-05T13:01:48.449570",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<span style=\"color:Olive; font-size:15px;\">\n",
    " Second step is to convert the whole text into a list of words, so that the stop words can be applied to them later\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-appeal",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-05T13:01:48.583575Z",
     "iopub.status.busy": "2021-05-05T13:01:48.582593Z",
     "iopub.status.idle": "2021-05-05T13:01:50.792949Z",
     "shell.execute_reply": "2021-05-05T13:01:50.793560Z"
    },
    "papermill": {
     "duration": 2.258676,
     "end_time": "2021-05-05T13:01:50.793761",
     "exception": false,
     "start_time": "2021-05-05T13:01:48.535085",
     "status": "completed"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def text_to_words(text):\n",
    "    words= text.split()\n",
    "    return words\n",
    "\n",
    "# column containing text converted to list of words\n",
    "combined_data[\"text_to_words\"]= combined_data[\"cleaned(only alphabets)\"].apply(lambda x : text_to_words(x))\n",
    "combined_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "still-working",
   "metadata": {
    "papermill": {
     "duration": 0.043247,
     "end_time": "2021-05-05T13:01:50.880115",
     "exception": false,
     "start_time": "2021-05-05T13:01:50.836868",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<span style=\"color:Olive; font-size:15px;\">\n",
    " Words like a, the , is , then etc are redundant and doesn't play any role in nlp, so it's better to remove these type of words. And stop words is the way to do that.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "labeled-thomson",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-05T13:01:50.971274Z",
     "iopub.status.busy": "2021-05-05T13:01:50.970347Z",
     "iopub.status.idle": "2021-05-05T14:03:25.799535Z",
     "shell.execute_reply": "2021-05-05T14:03:25.800050Z"
    },
    "papermill": {
     "duration": 3694.878341,
     "end_time": "2021-05-05T14:03:25.800294",
     "exception": false,
     "start_time": "2021-05-05T13:01:50.921953",
     "status": "completed"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def clean_words(word_list):\n",
    "    # applying stop words\n",
    "    word= [stemmer.stem(word) for word in word_list if not word in stopwords.words(\"english\")]\n",
    "    # joining them again\n",
    "    word= \" \".join(word)\n",
    "    return word  \n",
    "\n",
    "combined_data[\"cleaned_words\"]= combined_data[\"text_to_words\"].apply(lambda x: clean_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "round-final",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-05T14:03:25.915813Z",
     "iopub.status.busy": "2021-05-05T14:03:25.912437Z",
     "iopub.status.idle": "2021-05-05T14:03:25.921255Z",
     "shell.execute_reply": "2021-05-05T14:03:25.920669Z"
    },
    "papermill": {
     "duration": 0.075444,
     "end_time": "2021-05-05T14:03:25.921399",
     "exception": false,
     "start_time": "2021-05-05T14:03:25.845955",
     "status": "completed"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_data.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "current-lloyd",
   "metadata": {
    "papermill": {
     "duration": 0.044853,
     "end_time": "2021-05-05T14:03:26.012351",
     "exception": false,
     "start_time": "2021-05-05T14:03:25.967498",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<span style=\"color:Olive; font-size:15px;\">\n",
    "So we got our cleaned_words, create a function to count number of words it contains\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weekly-bundle",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-05T14:03:26.109722Z",
     "iopub.status.busy": "2021-05-05T14:03:26.108716Z",
     "iopub.status.idle": "2021-05-05T14:03:26.728895Z",
     "shell.execute_reply": "2021-05-05T14:03:26.729431Z"
    },
    "papermill": {
     "duration": 0.672388,
     "end_time": "2021-05-05T14:03:26.729600",
     "exception": false,
     "start_time": "2021-05-05T14:03:26.057212",
     "status": "completed"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def word_count(text):\n",
    "    text = str(text)\n",
    "    return len(text.split(' '))\n",
    "\n",
    "combined_data['word_count'] = combined_data['cleaned_words'].apply(word_count)\n",
    "combined_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premier-income",
   "metadata": {
    "papermill": {
     "duration": 0.045645,
     "end_time": "2021-05-05T14:03:26.821168",
     "exception": false,
     "start_time": "2021-05-05T14:03:26.775523",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<span style=\"color:Olive; font-size:15px;\">\n",
    "Let's have a look at what we have done till now. Let's compare the text before and after preprocessing \n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-transportation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-05T14:03:26.918175Z",
     "iopub.status.busy": "2021-05-05T14:03:26.917251Z",
     "iopub.status.idle": "2021-05-05T14:03:26.927880Z",
     "shell.execute_reply": "2021-05-05T14:03:26.928510Z"
    },
    "papermill": {
     "duration": 0.061487,
     "end_time": "2021-05-05T14:03:26.928669",
     "exception": false,
     "start_time": "2021-05-05T14:03:26.867182",
     "status": "completed"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Text Before Preprocessing :\\n\\n\", combined_data[\"text\"][0])\n",
    "print(\"\\n\\nText After Preprocessing :\\n\\n\",combined_data[\"cleaned_words\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspected-linux",
   "metadata": {
    "papermill": {
     "duration": 0.044298,
     "end_time": "2021-05-05T14:03:27.018893",
     "exception": false,
     "start_time": "2021-05-05T14:03:26.974595",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<span style=\"font-family:luxury; color:MediumVioletRed; font-size:30px;\"> Separating train and test dataset</span><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handmade-camcorder",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-05T14:03:27.117386Z",
     "iopub.status.busy": "2021-05-05T14:03:27.116000Z",
     "iopub.status.idle": "2021-05-05T14:03:27.131307Z",
     "shell.execute_reply": "2021-05-05T14:03:27.131862Z"
    },
    "papermill": {
     "duration": 0.068574,
     "end_time": "2021-05-05T14:03:27.132030",
     "exception": false,
     "start_time": "2021-05-05T14:03:27.063456",
     "status": "completed"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data= combined_data[combined_data[\"train/test\"] == \"train\"]\n",
    "test_data= combined_data[combined_data[\"train/test\"] == \"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paperback-annotation",
   "metadata": {
    "papermill": {
     "duration": 0.045143,
     "end_time": "2021-05-05T14:03:27.221889",
     "exception": false,
     "start_time": "2021-05-05T14:03:27.176746",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<span style=\"font-family:luxury; color:MediumVioletRed; font-size:25px;\"> Vector Representation of words</span><br>\n",
    "<span style=\"color:Olive; font-size:15px;\">\n",
    "Now we have to convert meaningful text into vector representation such that a machine can understand the pattern associated in any text and can make out the context of sentences.<br>\n",
    "And for this we will be using word embedding technique.    \n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elect-prairie",
   "metadata": {
    "papermill": {
     "duration": 0.044798,
     "end_time": "2021-05-05T14:03:27.312034",
     "exception": false,
     "start_time": "2021-05-05T14:03:27.267236",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<span style=\"font-family:luxury; color:MediumVioletRed; font-size:25px;\"> One-hot Encoding</span><br>\n",
    "<span style=\"color:Olive; font-size:15px;\">\n",
    "Before applying word embedding, words must be one-hot encoded\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-carter",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-05T14:03:27.407582Z",
     "iopub.status.busy": "2021-05-05T14:03:27.406900Z",
     "iopub.status.idle": "2021-05-05T14:03:40.420415Z",
     "shell.execute_reply": "2021-05-05T14:03:40.419840Z"
    },
    "papermill": {
     "duration": 13.063385,
     "end_time": "2021-05-05T14:03:40.420558",
     "exception": false,
     "start_time": "2021-05-05T14:03:27.357173",
     "status": "completed"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import one_hot\n",
    "vocab_size= 10000\n",
    "\n",
    "# one-hot encoding train_data\n",
    "trainWords_to_list= []\n",
    "for i in range(0, len(train_data)):\n",
    "    trainWords_to_list.append(train_data[\"cleaned_words\"][i])\n",
    "    \n",
    "encoded_train= [one_hot(word, vocab_size) for word in trainWords_to_list]\n",
    "\n",
    "\n",
    "# one-hot encoding test_data\n",
    "testWords_to_list= []\n",
    "for i in range(0, len(test_data)):\n",
    "    testWords_to_list.append(test_data[\"cleaned_words\"][i])\n",
    "    \n",
    "encoded_test= [one_hot(word, vocab_size) for word in testWords_to_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closing-traffic",
   "metadata": {
    "papermill": {
     "duration": 0.043983,
     "end_time": "2021-05-05T14:03:40.510979",
     "exception": false,
     "start_time": "2021-05-05T14:03:40.466996",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<span style=\"color:Olive; font-size:15px;\">\n",
    "This is how one-hot encoded text looks like. Each word is represented by it's index number present in the vocabulary size.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legitimate-eugene",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-05T14:03:40.618726Z",
     "iopub.status.busy": "2021-05-05T14:03:40.617507Z",
     "iopub.status.idle": "2021-05-05T14:03:40.623055Z",
     "shell.execute_reply": "2021-05-05T14:03:40.622431Z"
    },
    "papermill": {
     "duration": 0.066725,
     "end_time": "2021-05-05T14:03:40.623229",
     "exception": false,
     "start_time": "2021-05-05T14:03:40.556504",
     "status": "completed"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoded_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geographic-layer",
   "metadata": {
    "papermill": {
     "duration": 0.045745,
     "end_time": "2021-05-05T14:03:40.716664",
     "exception": false,
     "start_time": "2021-05-05T14:03:40.670919",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<span style=\"font-family:luxury; color:MediumVioletRed; font-size:25px;\"> Text Padding</span><br>\n",
    "<span style=\"color:Olive; font-size:15px;\">\n",
    "Model require to have inputs with the same shape and size. And not all the sentences have the same length. So we need to do padding.<br>\n",
    "    Padding is done by adding zeros for short sentences(pre or post the sentence) and truncating the sentences which exceed the max number of words which is declared by \"maxlen\".\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "novel-faculty",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-05T14:03:40.811819Z",
     "iopub.status.busy": "2021-05-05T14:03:40.810871Z",
     "iopub.status.idle": "2021-05-05T14:03:42.401149Z",
     "shell.execute_reply": "2021-05-05T14:03:42.402255Z"
    },
    "papermill": {
     "duration": 1.641102,
     "end_time": "2021-05-05T14:03:42.402619",
     "exception": false,
     "start_time": "2021-05-05T14:03:40.761517",
     "status": "completed"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "text_length= 500\n",
    "\n",
    "# applying padding to one-hot encoded train_data\n",
    "padded_train= pad_sequences(encoded_train, padding= \"pre\", maxlen=text_length)\n",
    "\n",
    "# applying padding to one-hot encoded test_data\n",
    "padded_test= pad_sequences(encoded_test, padding= \"pre\", maxlen=text_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opened-muscle",
   "metadata": {
    "papermill": {
     "duration": 0.078423,
     "end_time": "2021-05-05T14:03:42.566362",
     "exception": false,
     "start_time": "2021-05-05T14:03:42.487939",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<span style=\"color:Olive; font-size:15px;\">\n",
    "It can be seen that in the first text of train_data, zeros have been added to make it equal to text_length=500\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interpreted-glucose",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-05T14:03:42.733217Z",
     "iopub.status.busy": "2021-05-05T14:03:42.732201Z",
     "iopub.status.idle": "2021-05-05T14:03:42.739666Z",
     "shell.execute_reply": "2021-05-05T14:03:42.740560Z"
    },
    "papermill": {
     "duration": 0.094992,
     "end_time": "2021-05-05T14:03:42.740739",
     "exception": false,
     "start_time": "2021-05-05T14:03:42.645747",
     "status": "completed"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "padded_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designed-cosmetic",
   "metadata": {
    "papermill": {
     "duration": 0.088517,
     "end_time": "2021-05-05T14:03:42.907740",
     "exception": false,
     "start_time": "2021-05-05T14:03:42.819223",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<span style=\"color:Olive; font-size:15px;\">\n",
    "But in test_data, we cannot see any zeros. This is because the length of this text is already greater than mentioned text_length= 500. So instead it's length have been truncated to make it equal 500.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "labeled-snapshot",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-05T14:03:43.079563Z",
     "iopub.status.busy": "2021-05-05T14:03:43.078640Z",
     "iopub.status.idle": "2021-05-05T14:03:43.085232Z",
     "shell.execute_reply": "2021-05-05T14:03:43.085900Z"
    },
    "papermill": {
     "duration": 0.09432,
     "end_time": "2021-05-05T14:03:43.086130",
     "exception": false,
     "start_time": "2021-05-05T14:03:42.991810",
     "status": "completed"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "padded_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coated-coordinate",
   "metadata": {
    "papermill": {
     "duration": 0.070491,
     "end_time": "2021-05-05T14:03:43.234051",
     "exception": false,
     "start_time": "2021-05-05T14:03:43.163560",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<span style=\"font-family:luxury; color:MediumVioletRed; font-size:30px;\">Creating Feature and Target for train_data</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handmade-south",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-05T14:03:43.378664Z",
     "iopub.status.busy": "2021-05-05T14:03:43.377736Z",
     "iopub.status.idle": "2021-05-05T14:03:43.394042Z",
     "shell.execute_reply": "2021-05-05T14:03:43.395282Z"
    },
    "papermill": {
     "duration": 0.101872,
     "end_time": "2021-05-05T14:03:43.395534",
     "exception": false,
     "start_time": "2021-05-05T14:03:43.293662",
     "status": "completed"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "feature= np.array(padded_train)\n",
    "target= np.array(train[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affected-guidance",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-05T14:03:43.560727Z",
     "iopub.status.busy": "2021-05-05T14:03:43.557293Z",
     "iopub.status.idle": "2021-05-05T14:03:43.568611Z",
     "shell.execute_reply": "2021-05-05T14:03:43.565545Z"
    },
    "papermill": {
     "duration": 0.101334,
     "end_time": "2021-05-05T14:03:43.569129",
     "exception": false,
     "start_time": "2021-05-05T14:03:43.467795",
     "status": "completed"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"shape of feature\", feature.shape)\n",
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strategic-minute",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-05T14:03:43.678592Z",
     "iopub.status.busy": "2021-05-05T14:03:43.677635Z",
     "iopub.status.idle": "2021-05-05T14:03:43.684056Z",
     "shell.execute_reply": "2021-05-05T14:03:43.683507Z"
    },
    "papermill": {
     "duration": 0.062978,
     "end_time": "2021-05-05T14:03:43.684207",
     "exception": false,
     "start_time": "2021-05-05T14:03:43.621229",
     "status": "completed"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"shape of target\", target.shape)\n",
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriented-queens",
   "metadata": {
    "papermill": {
     "duration": 0.048461,
     "end_time": "2021-05-05T14:03:43.782568",
     "exception": false,
     "start_time": "2021-05-05T14:03:43.734107",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<span style=\"color:Olive; font-size:15px;\">\n",
    "Since the test data doesn't have \"label\" column in it, so we need to create a validation data from train_data for training purpose.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excellent-single",
   "metadata": {
    "papermill": {
     "duration": 0.048862,
     "end_time": "2021-05-05T14:03:43.881333",
     "exception": false,
     "start_time": "2021-05-05T14:03:43.832471",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<span style=\"font-family:luxury; color:MediumVioletRed; font-size:25px;\">Splitting train_data into train and validation set</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "characteristic-earth",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-05T14:03:43.988843Z",
     "iopub.status.busy": "2021-05-05T14:03:43.987537Z",
     "iopub.status.idle": "2021-05-05T14:03:44.010309Z",
     "shell.execute_reply": "2021-05-05T14:03:44.009645Z"
    },
    "papermill": {
     "duration": 0.079284,
     "end_time": "2021-05-05T14:03:44.010471",
     "exception": false,
     "start_time": "2021-05-05T14:03:43.931187",
     "status": "completed"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(feature, target, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affected-respect",
   "metadata": {
    "papermill": {
     "duration": 0.050007,
     "end_time": "2021-05-05T14:03:44.111205",
     "exception": false,
     "start_time": "2021-05-05T14:03:44.061198",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<span style=\"font-family:luxury; color:MediumVioletRed; font-size:30px;\">Model Building</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-musician",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-05T14:03:44.217817Z",
     "iopub.status.busy": "2021-05-05T14:03:44.216983Z",
     "iopub.status.idle": "2021-05-05T14:03:47.475664Z",
     "shell.execute_reply": "2021-05-05T14:03:47.476455Z"
    },
    "papermill": {
     "duration": 3.315713,
     "end_time": "2021-05-05T14:03:47.476725",
     "exception": false,
     "start_time": "2021-05-05T14:03:44.161012",
     "status": "completed"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dense, Dropout, LSTM\n",
    "\n",
    "# number of features is required to be mentioned in order to convert word into it's vector form \n",
    "embedding_features= 30\n",
    "\n",
    "model= Sequential()\n",
    "# this layer converts padded data into vectors\n",
    "model.add(Embedding(vocab_size, embedding_features, input_length= text_length))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# LSTM layer with 100 neurons\n",
    "model.add(LSTM(units= 50))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dimensional-verification",
   "metadata": {
    "papermill": {
     "duration": 0.049703,
     "end_time": "2021-05-05T14:03:47.609702",
     "exception": false,
     "start_time": "2021-05-05T14:03:47.559999",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<span style=\"font-family:luxury; color:MediumVioletRed; font-size:30px;\">Model Training</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disabled-bradley",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-05T14:03:47.720013Z",
     "iopub.status.busy": "2021-05-05T14:03:47.719106Z",
     "iopub.status.idle": "2021-05-05T14:05:01.977695Z",
     "shell.execute_reply": "2021-05-05T14:05:01.978315Z"
    },
    "papermill": {
     "duration": 74.320176,
     "end_time": "2021-05-05T14:05:01.978518",
     "exception": false,
     "start_time": "2021-05-05T14:03:47.658342",
     "status": "completed"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(loss= \"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "history= model.fit(x_train, y_train,\n",
    "          validation_data= (x_val, y_val),\n",
    "          batch_size= 100, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qualified-treasury",
   "metadata": {
    "papermill": {
     "duration": 0.343986,
     "end_time": "2021-05-05T14:05:02.660807",
     "exception": false,
     "start_time": "2021-05-05T14:05:02.316821",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<span style=\"font-family:luxury; color:MediumVioletRed; font-size:30px;\">Model Evaluation</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stupid-morning",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-05T14:05:03.342894Z",
     "iopub.status.busy": "2021-05-05T14:05:03.341970Z",
     "iopub.status.idle": "2021-05-05T14:05:03.345919Z",
     "shell.execute_reply": "2021-05-05T14:05:03.346499Z"
    },
    "papermill": {
     "duration": 0.350684,
     "end_time": "2021-05-05T14:05:03.346650",
     "exception": false,
     "start_time": "2021-05-05T14:05:02.995966",
     "status": "completed"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-makeup",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-05T14:05:04.049939Z",
     "iopub.status.busy": "2021-05-05T14:05:04.048764Z",
     "iopub.status.idle": "2021-05-05T14:05:04.437277Z",
     "shell.execute_reply": "2021-05-05T14:05:04.437777Z"
    },
    "papermill": {
     "duration": 0.752952,
     "end_time": "2021-05-05T14:05:04.437982",
     "exception": false,
     "start_time": "2021-05-05T14:05:03.685030",
     "status": "completed"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "epochs= range(len(history.history[\"accuracy\"]))\n",
    "# accuracy plot\n",
    "plt.plot(epochs, history.history[\"accuracy\"])\n",
    "plt.plot(epochs, history.history[\"val_accuracy\"])\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend([\"train_data\", \"validation_data\"])\n",
    "plt.show()\n",
    "\n",
    "# loss plot\n",
    "plt.plot(epochs, history.history[\"loss\"])\n",
    "plt.plot(epochs, history.history[\"val_loss\"])\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.legend([\"train_data\", \"validation_data\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saving-cooperative",
   "metadata": {
    "papermill": {
     "duration": 0.332558,
     "end_time": "2021-05-05T14:05:05.113142",
     "exception": false,
     "start_time": "2021-05-05T14:05:04.780584",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<span style=\"font-family:luxury; color:MediumVioletRed; font-size:20px;\">Checking model performance through validation data </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "usual-accountability",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-05T14:05:05.801269Z",
     "iopub.status.busy": "2021-05-05T14:05:05.799945Z",
     "iopub.status.idle": "2021-05-05T14:05:07.829204Z",
     "shell.execute_reply": "2021-05-05T14:05:07.829731Z"
    },
    "papermill": {
     "duration": 2.378965,
     "end_time": "2021-05-05T14:05:07.829910",
     "exception": false,
     "start_time": "2021-05-05T14:05:05.450945",
     "status": "completed"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_val= model.predict_classes(x_val)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n",
    "cm= confusion_matrix(y_val, pred_val)\n",
    "plot_confusion_matrix(cm, figsize=(5,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weighted-racing",
   "metadata": {
    "papermill": {
     "duration": 0.345123,
     "end_time": "2021-05-05T14:05:08.525531",
     "exception": false,
     "start_time": "2021-05-05T14:05:08.180408",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<span style=\"font-family:luxury; color:MediumVioletRed; font-size:30px;\">Submission</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-patent",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-05T14:05:09.221189Z",
     "iopub.status.busy": "2021-05-05T14:05:09.219760Z",
     "iopub.status.idle": "2021-05-05T14:05:11.559931Z",
     "shell.execute_reply": "2021-05-05T14:05:11.558957Z"
    },
    "papermill": {
     "duration": 2.692964,
     "end_time": "2021-05-05T14:05:11.560151",
     "exception": false,
     "start_time": "2021-05-05T14:05:08.867187",
     "status": "completed"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_array= np.array(padded_test)\n",
    "prediction_test= model.predict_classes(test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funded-gossip",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-05T14:05:12.256544Z",
     "iopub.status.busy": "2021-05-05T14:05:12.255464Z",
     "iopub.status.idle": "2021-05-05T14:05:12.443658Z",
     "shell.execute_reply": "2021-05-05T14:05:12.444292Z"
    },
    "papermill": {
     "duration": 0.542019,
     "end_time": "2021-05-05T14:05:12.444505",
     "exception": false,
     "start_time": "2021-05-05T14:05:11.902486",
     "status": "completed"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission= pd.DataFrame()\n",
    "submission[\"id\"]= test[\"id\"]\n",
    "submission[\"label\"]= prediction_test\n",
    "submission.to_csv(\"LSTM_model.csv\", index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-witness",
   "metadata": {
    "papermill": {
     "duration": 0.356748,
     "end_time": "2021-05-05T14:05:13.160160",
     "exception": false,
     "start_time": "2021-05-05T14:05:12.803412",
     "status": "completed"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3833.558263,
   "end_time": "2021-05-05T14:05:17.712162",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-05T13:01:24.153899",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
